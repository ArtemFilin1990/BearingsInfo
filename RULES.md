# Правила работы с данными

## Достоверность
- Источник истины — файлы в `sources/` и их метаданные `meta.yaml`.
- Любая новая строка в CSV должна иметь ссылку на источник (колонка `source`).
- Запрещены вымышленные значения и расчёты без подтверждения в исходниках.

## Формат данных
- Разделитель: запятая. Кодировки: UTF-8, завершающие переводы строк обязательны.
- Числа: десятичная точка, без пробелов и разделителей тысяч.
- Пустые значения: пустая строка (`""`), не использовать `-`, `NULL`, `N/A`.
- Стабильная сортировка: по ключам из `schemas/*.yaml`; менять порядок руками запрещено.
- Уникальные ключи: `(gost, iso)` для аналогов, `(code, manufacturer)` для суффиксов, `(designation, d, D, B)` для размеров, `brand` для брендов.

## Процесс обновления
1. Поместите новый PDF/DOCX в `sources/<category>/` и добавьте запись в `meta.yaml`.
2. Обновите сырые таблицы в `scripts/extract/raw_datasets.py` с указанием источника.
3. Запустите:
   ```bash
   python scripts/update_repo.py         # нормализация CSV
   python scripts/validate/run_validations.py
   python -m pytest -q
   ```
4. Добавьте отчёт в `data/reports/YYYY-MM-DD_source.json` с входными/выходными файлами и статистикой строк.

## Контроль качества
- Валидации: `scripts/validate/csv_validator.py` проверяет схему, сортировку, типы и дубликаты.
- CI: `.github/workflows/ci.yml` запускает нормализацию, валидации и тесты на каждом push/PR.
- Любое нарушение правил формата считается блокирующим и должно быть исправлено до коммита.
