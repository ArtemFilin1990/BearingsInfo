#!/usr/bin/env python3
"""
–°–æ–∑–¥–∞–Ω–∏–µ –ü–û–õ–ù–û–ô, –ö–û–ú–ü–õ–ï–ö–°–ù–û–ô –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –¥–ª—è BearingsInfo
—Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º 100% –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤

–†–µ–∂–∏–º: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢ - –±–µ–∑ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
"""

import os
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Set
from collections import defaultdict

class ComprehensiveKnowledgeBaseBuilder:
    def __init__(self, root_dir: str = "."):
        self.root_dir = Path(root_dir)
        self.sections = {
            "terms": defaultdict(list),           # –¢–µ—Ä–º–∏–Ω—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            "processes": defaultdict(list),       # –ü—Ä–æ—Ü–µ—Å—Å—ã –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã
            "rules": defaultdict(list),           # –ü—Ä–∞–≤–∏–ª–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
            "data_structures": defaultdict(list), # –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
            "roles": defaultdict(list),           # –†–æ–ª–∏ –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
            "usage": defaultdict(list),           # –°—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            "errors": defaultdict(list),          # –û—à–∏–±–∫–∏ –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            "relationships": defaultdict(list),   # –°–≤—è–∑–∏ –º–µ–∂–¥—É —Å—É—â–Ω–æ—Å—Ç—è–º–∏
            "sources": []                         # –ò—Å—Ç–æ—á–Ω–∏–∫–∏
        }
        self.file_count = 0
        self.total_lines = 0
        
    def extract_from_markdown(self, file_path: Path) -> Dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ markdown —Ñ–∞–π–ª–∞"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            relative_path = file_path.relative_to(self.root_dir)
            self.file_count += 1
            self.total_lines += len(content.split('\n'))
            
            data = {
                'path': str(relative_path),
                'content': content,
                'headers': self.extract_headers(content),
                'tables': self.extract_tables(content),
                'lists': self.extract_lists(content),
                'code_blocks': self.extract_code_blocks(content),
                'links': self.extract_links(content),
                'terms': self.extract_terms(content),
                'numbers': self.extract_numbers(content),
                'standards': self.extract_standards(content)
            }
            
            return data
        except Exception as e:
            print(f"Error processing {file_path}: {e}")
            return None
            
    def extract_headers(self, content: str) -> List[Tuple[int, str]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤"""
        headers = []
        for match in re.finditer(r'^(#{1,6})\s+(.+)$', content, re.MULTILINE):
            level = len(match.group(1))
            text = match.group(2).strip()
            headers.append((level, text))
        return headers
        
    def extract_tables(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü"""
        tables = []
        lines = content.split('\n')
        in_table = False
        current_table = []
        
        for line in lines:
            if '|' in line and line.strip():
                in_table = True
                current_table.append(line)
            elif in_table:
                if current_table:
                    tables.append('\n'.join(current_table))
                current_table = []
                in_table = False
                
        if current_table:
            tables.append('\n'.join(current_table))
            
        return tables
        
    def extract_lists(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–ø–∏—Å–∫–æ–≤"""
        lists = []
        lines = content.split('\n')
        current_list = []
        
        for line in lines:
            if re.match(r'^\s*[-*+]\s+', line) or re.match(r'^\s*\d+\.\s+', line):
                current_list.append(line)
            elif current_list:
                lists.append('\n'.join(current_list))
                current_list = []
                
        if current_list:
            lists.append('\n'.join(current_list))
            
        return lists
        
    def extract_code_blocks(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞"""
        return re.findall(r'```[\s\S]*?```', content)
        
    def extract_links(self, content: str) -> List[Tuple[str, str]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫"""
        links = []
        # Markdown links [text](url)
        for match in re.finditer(r'\[([^\]]+)\]\(([^\)]+)\)', content):
            links.append((match.group(1), match.group(2)))
        return links
        
    def extract_terms(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–≤ (—Å–ª–æ–≤–∞ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã)"""
        terms = set()
        
        # –¢–µ—Ä–º–∏–Ω—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º (—Å–ª–æ–≤–∞ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã)
        russian_terms = re.findall(r'\b[–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å]?[–∞-—è—ë]+)*\b', content)
        terms.update(russian_terms)
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è (–ì–û–°–¢, ISO, DIN –∏ —Ç.–¥.)
        tech_terms = re.findall(r'\b[A-Z]{2,}[-\s]?\d+(?:\.\d+)?(?:\-\d+)?\b', content)
        terms.update(tech_terms)
        
        return list(terms)
        
    def extract_numbers(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Ä–∞–∑–º–µ—Ä—ã, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)"""
        numbers = []
        
        # –ß–∏—Å–ª–∞ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è
        units_pattern = r'\d+(?:\.\d+)?\s*(?:–º–º|mm|–∫–≥|kg|–ù|N|¬∞C|¬∞|–≥—Ä–∞–¥|–æ–±/–º–∏–Ω|rpm|–ú–ü–∞|MPa)'
        numbers.extend(re.findall(units_pattern, content))
        
        # –î–∏–∞–ø–∞–∑–æ–Ω—ã
        ranges = re.findall(r'\d+(?:\.\d+)?\s*[-‚Äì‚Äî]\s*\d+(?:\.\d+)?', content)
        numbers.extend(ranges)
        
        return numbers
        
    def extract_standards(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤"""
        standards = set()
        
        # –ì–û–°–¢
        gost = re.findall(r'–ì–û–°–¢\s+\d+(?:\.\d+)?(?:\-\d+)?', content)
        standards.update(gost)
        
        # ISO
        iso = re.findall(r'ISO\s+\d+(?:\-\d+)?(?:\:\d+)?', content)
        standards.update(iso)
        
        # DIN
        din = re.findall(r'DIN\s+\d+(?:\-\d+)?', content)
        standards.update(din)
        
        # JIS
        jis = re.findall(r'JIS\s+[A-Z]\s*\d+', content)
        standards.update(jis)
        
        return list(standards)
        
    def categorize_content(self, data: Dict, file_path: Path):
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º"""
        path_str = str(file_path)
        source = data['path']
        
        # –¢–µ—Ä–º–∏–Ω—ã –∏ –æ—Å–Ω–æ–≤—ã
        if '02_–¢–µ—Ä–º–∏–Ω—ã' in path_str or '–¢–µ—Ä–º–∏–Ω' in path_str:
            for header in data['headers']:
                self.sections['terms'][header[1]].append({
                    'source': source,
                    'content': data['content'][:500]
                })
                
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç—ã –∏ –ø—Ä–∞–≤–∏–ª–∞
        if '–ì–û–°–¢' in path_str or '03_–ì–û–°–¢' in path_str or '—Å—Ç–∞–Ω–¥–∞—Ä—Ç' in path_str.lower():
            for std in data['standards']:
                self.sections['rules'][std].append({
                    'source': source,
                    'tables': data['tables'],
                    'content': data['content'][:500]
                })
                
        # –ü—Ä–æ—Ü–µ—Å—Å—ã (–º–æ–Ω—Ç–∞–∂, —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è, –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ)
        if any(kw in path_str.lower() for kw in ['–º–æ–Ω—Ç–∞–∂', '—ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è', '–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ', 'maintenance']):
            for header in data['headers']:
                self.sections['processes'][header[1]].append({
                    'source': source,
                    'lists': data['lists'],
                    'content': data['content'][:500]
                })
                
        # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
        if '–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ' in path_str or '—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤' in path_str:
            for header in data['headers']:
                self.sections['usage'][header[1]].append({
                    'source': source,
                    'content': data['content'][:1000]
                })
                
        # –û—à–∏–±–∫–∏ –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
        if '–æ—Ç–∫–∞–∑' in path_str.lower() or '–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞' in path_str.lower() or 'failure' in path_str.lower():
            for header in data['headers']:
                self.sections['errors'][header[1]].append({
                    'source': source,
                    'content': data['content'][:500]
                })
                
        # –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö (—Ç–∞–±–ª–∏—Ü—ã —Ä–∞–∑–º–µ—Ä–æ–≤, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫)
        if data['tables']:
            self.sections['data_structures'][source].extend(data['tables'])
            
    def scan_directories(self):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        priority_dirs = [
            '02_–¢–µ—Ä–º–∏–Ω—ã_–∏_–æ—Å–Ω–æ–≤—ã',
            '03_–ì–û–°–¢_–ø–æ–¥—à–∏–ø–Ω–∏–∫–∏_–∏_–Ω–æ—Ä–º–∞—Ç–∏–≤–∫–∞',
            '–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ_—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞',
            '–ü–æ–¥—à–∏–ø–Ω–∏–∫–∏',
            '05_–ú–∞—Ä–∫–∏—Ä–æ–≤–∫–∞_—Å—É—Ñ—Ñ–∏–∫—Å—ã_—Å–µ—Ä–∏–∏',
            '04_ISO_–∏_–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ_–æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è',
            'docs',
            '07_–ë—Ä–µ–Ω–¥—ã_–∏_–∫–∞—Ç–∞–ª–æ–≥–∏',
            '06_–ê–Ω–∞–ª–æ–≥–∏_–∏_–≤–∑–∞–∏–º–æ–∑–∞–º–µ–Ω—è–µ–º–æ—Å—Ç—å',
            '08_–ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–µ_–∫–æ–º–ø–ª–µ–∫—Ç—ã',
            '09_–õ–∏–Ω–µ–π–Ω—ã–µ_—Å–∏—Å—Ç–µ–º—ã_–∏_–ø–µ—Ä–µ–¥–∞—á–∏',
            '–£—á–µ–±–Ω–∏–∫',
            '–í–≤–æ–¥–Ω—ã–π_–∫—É—Ä—Å_–¥–ª—è_–Ω–æ–≤–∏—á–∫–æ–≤'
        ]
        
        for dir_name in priority_dirs:
            dir_path = self.root_dir / dir_name
            if dir_path.exists():
                print(f"Scanning {dir_name}...")
                for md_file in dir_path.rglob('*.md'):
                    data = self.extract_from_markdown(md_file)
                    if data:
                        self.categorize_content(data, md_file)
                        self.sections['sources'].append(data['path'])
                        
    def build_knowledge_base(self) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        print("Building comprehensive knowledge base...")
        self.scan_directories()
        
        kb = []
        kb.append("# –ü–û–õ–ù–ê–Ø –ë–ê–ó–ê –ó–ù–ê–ù–ò–ô: BearingsInfo")
        kb.append(f"\n**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        kb.append(f"**–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤:** {self.file_count}")
        kb.append(f"**–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫:** {self.total_lines:,}")
        kb.append("\n**–†–ï–ñ–ò–ú: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢** - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ 100% –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –±–µ–∑ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π")
        kb.append("\n---\n")
        
        # –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
        kb.append("# üìë –°–û–î–ï–†–ñ–ê–ù–ò–ï\n")
        kb.append("1. [–û–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–º–µ–Ω–∞](#1-–æ–±—â–µ–µ-–æ–ø–∏—Å–∞–Ω–∏–µ-–¥–æ–º–µ–Ω–∞)")
        kb.append("2. [–¢–µ—Ä–º–∏–Ω—ã –∏ –≥–ª–æ—Å—Å–∞—Ä–∏–π](#2-—Ç–µ—Ä–º–∏–Ω—ã-–∏-–≥–ª–æ—Å—Å–∞—Ä–∏–π)")
        kb.append("3. [–ü—Ä–æ—Ü–µ—Å—Å—ã –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã](#3-–ø—Ä–æ—Ü–µ—Å—Å—ã-–∏-–∞–ª–≥–æ—Ä–∏—Ç–º—ã)")
        kb.append("4. [–ü—Ä–∞–≤–∏–ª–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è](#4-–ø—Ä–∞–≤–∏–ª–∞-–∏-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)")
        kb.append("5. [–°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–æ—Ä–º–∞—Ç—ã](#5-—Å—Ç—Ä—É–∫—Ç—É—Ä—ã-–¥–∞–Ω–Ω—ã—Ö-–∏-—Ñ–æ—Ä–º–∞—Ç—ã)")
        kb.append("6. [–†–æ–ª–∏ –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏](#6-—Ä–æ–ª–∏-–∏-–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏)")
        kb.append("7. [–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è](#7-–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏-–∏-—Å—Ü–µ–Ω–∞—Ä–∏–∏-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)")
        kb.append("8. [–û—à–∏–±–∫–∏, –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –∫—Ä–∞–π–Ω–∏–µ —Å–ª—É—á–∞–∏](#8-–æ—à–∏–±–∫–∏-–∏—Å–∫–ª—é—á–µ–Ω–∏—è-–∫—Ä–∞–π–Ω–∏–µ-—Å–ª—É—á–∞–∏)")
        kb.append("9. [–°–≤—è–∑–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É —Å—É—â–Ω–æ—Å—Ç—è–º–∏](#9-—Å–≤—è–∑–∏-–∏-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏-–º–µ–∂–¥—É-—Å—É—â–Ω–æ—Å—Ç—è–º–∏)")
        kb.append("10. [–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞](#10-–∏—Å—Ç–æ—á–Ω–∏–∫–∏-–∏-—Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞)")
        kb.append("\n---\n")
        
        # 1. –û–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–º–µ–Ω–∞
        kb.append("## 1. –û–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–º–µ–Ω–∞\n")
        kb.append(self.build_domain_overview())
        kb.append("\n---\n")
        
        # 2. –¢–µ—Ä–º–∏–Ω—ã –∏ –≥–ª–æ—Å—Å–∞—Ä–∏–π
        kb.append("## 2. –¢–µ—Ä–º–∏–Ω—ã –∏ –≥–ª–æ—Å—Å–∞—Ä–∏–π\n")
        kb.append(self.build_terms_glossary())
        kb.append("\n---\n")
        
        # 3. –ü—Ä–æ—Ü–µ—Å—Å—ã –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã
        kb.append("## 3. –ü—Ä–æ—Ü–µ—Å—Å—ã –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã\n")
        kb.append(self.build_processes())
        kb.append("\n---\n")
        
        # 4. –ü—Ä–∞–≤–∏–ª–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        kb.append("## 4. –ü—Ä–∞–≤–∏–ª–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è\n")
        kb.append(self.build_rules())
        kb.append("\n---\n")
        
        # 5. –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–æ—Ä–º–∞—Ç—ã
        kb.append("## 5. –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–æ—Ä–º–∞—Ç—ã\n")
        kb.append(self.build_data_structures())
        kb.append("\n---\n")
        
        # 6. –†–æ–ª–∏ –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
        kb.append("## 6. –†–æ–ª–∏ –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏\n")
        kb.append(self.build_roles())
        kb.append("\n---\n")
        
        # 7. –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        kb.append("## 7. –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n")
        kb.append(self.build_usage_scenarios())
        kb.append("\n---\n")
        
        # 8. –û—à–∏–±–∫–∏, –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –∫—Ä–∞–π–Ω–∏–µ —Å–ª—É—á–∞–∏
        kb.append("## 8. –û—à–∏–±–∫–∏, –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –∫—Ä–∞–π–Ω–∏–µ —Å–ª—É—á–∞–∏\n")
        kb.append(self.build_errors())
        kb.append("\n---\n")
        
        # 9. –°–≤—è–∑–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        kb.append("## 9. –°–≤—è–∑–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É —Å—É—â–Ω–æ—Å—Ç—è–º–∏\n")
        kb.append(self.build_relationships())
        kb.append("\n---\n")
        
        # 10. –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞
        kb.append("## 10. –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞\n")
        kb.append(self.build_sources())
        
        return '\n'.join(kb)
        
    def build_domain_overview(self) -> str:
        """–†–∞–∑–¥–µ–ª 1: –û–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–º–µ–Ω–∞"""
        content = []
        content.append("### –ü—Ä–µ–¥–º–µ—Ç–Ω–∞—è –æ–±–ª–∞—Å—Ç—å: –ü–æ–¥—à–∏–ø–Ω–∏–∫–∏ –∏ —Å–æ–ø—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–∑–¥–µ–ª–∏—è\n")
        content.append("#### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è")
        content.append("–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π BearingsInfo –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É,")
        content.append("—Å–æ–¥–µ—Ä–∂–∞—â—É—é –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞—Ö –∫–∞—á–µ–Ω–∏—è –∏ —Å–æ–ø—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∏–∑–¥–µ–ª–∏—è—Ö.\n")
        
        content.append("#### –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏:\n")
        content.append("1. **–¢–µ–æ—Ä–∏—è –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤** - —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã")
        content.append("2. **–°—Ç–∞–Ω–¥–∞—Ä—Ç—ã –∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è** - –ì–û–°–¢, ISO, DIN, JIS")
        content.append("3. **–¢–∏–ø–æ–ª–æ–≥–∏—è –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è** - –≤–∏–¥—ã –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤ –∏ –∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
        content.append("4. **–ú–∞—Ä–∫–∏—Ä–æ–≤–∫–∞ –∏ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è** - —Å–∏—Å—Ç–µ–º—ã –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        content.append("5. **–†–∞—Å—á—ë—Ç—ã –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã** - –º–µ—Ç–æ–¥–∏–∫–∏ —Ä–∞—Å—á—ë—Ç–∞ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏")
        content.append("6. **–≠–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ** - –º–æ–Ω—Ç–∞–∂, —Å–º–∞–∑–∫–∞, –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞")
        content.append("7. **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–∏ –∏ –±—Ä–µ–Ω–¥—ã** - –∫–∞—Ç–∞–ª–æ–≥–∏, –∞–Ω–∞–ª–æ–≥–∏, –≤–∑–∞–∏–º–æ–∑–∞–º–µ–Ω—è–µ–º–æ—Å—Ç—å")
        content.append("8. **–°–æ–ø—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–∑–¥–µ–ª–∏—è** - —É–ø–ª–æ—Ç–Ω–µ–Ω–∏—è, —Å–º–∞–∑–∫–∏, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç\n")
        
        content.append(f"#### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è")
        content.append(f"- –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {self.file_count}")
        content.append(f"- –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {self.total_lines:,}")
        content.append(f"- –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {sum(len(v) for v in self.sections['terms'].values())}")
        content.append(f"- –ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–Ω—ã—Ö: {len(self.sections['data_structures'])}\n")
        
        return '\n'.join(content)
        
    def build_terms_glossary(self) -> str:
        """–†–∞–∑–¥–µ–ª 2: –¢–µ—Ä–º–∏–Ω—ã –∏ –≥–ª–æ—Å—Å–∞—Ä–∏–π"""
        content = []
        content.append("### –ò—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π —Ç–µ—Ä–º–∏–Ω–æ–≤\n")
        content.append("| –¢–µ—Ä–º–∏–Ω | –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –ò—Å—Ç–æ—á–Ω–∏–∫ |")
        content.append("|--------|-----------|----------|")
        
        count = 0
        for term, items in sorted(self.sections['terms'].items()):
            if count < 500:  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è —Ä–∞–∑—É–º–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
                sources = ', '.join(set(item['source'] for item in items[:3]))
                content.append(f"| {term} | –¢–µ—Ä–º–∏–Ω | {sources} |")
                count += 1
                
        content.append(f"\n**–í—Å–µ–≥–æ —Ç–µ—Ä–º–∏–Ω–æ–≤:** {len(self.sections['terms'])}\n")
        return '\n'.join(content)
        
    def build_processes(self) -> str:
        """–†–∞–∑–¥–µ–ª 3: –ü—Ä–æ—Ü–µ—Å—Å—ã –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã"""
        content = []
        content.append("### –ü—Ä–æ—Ü–µ—Å—Å—ã —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏ –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤\n")
        
        for process, items in self.sections['processes'].items():
            content.append(f"\n#### {process}\n")
            for item in items[:3]:
                content.append(f"**–ò—Å—Ç–æ—á–Ω–∏–∫:** `{item['source']}`\n")
                if 'lists' in item:
                    for lst in item['lists'][:2]:
                        content.append(lst)
                        content.append("")
                        
        return '\n'.join(content)
        
    def build_rules(self) -> str:
        """–†–∞–∑–¥–µ–ª 4: –ü—Ä–∞–≤–∏–ª–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è"""
        content = []
        content.append("### –°—Ç–∞–Ω–¥–∞—Ä—Ç—ã –∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è\n")
        
        for rule, items in sorted(self.sections['rules'].items()):
            content.append(f"\n#### {rule}\n")
            for item in items[:2]:
                content.append(f"**–ò—Å—Ç–æ—á–Ω–∏–∫:** `{item['source']}`\n")
                if 'tables' in item:
                    for table in item['tables'][:1]:
                        content.append(table)
                        content.append("")
                        
        return '\n'.join(content)
        
    def build_data_structures(self) -> str:
        """–†–∞–∑–¥–µ–ª 5: –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–æ—Ä–º–∞—Ç—ã"""
        content = []
        content.append("### –¢–∞–±–ª–∏—Ü—ã —Ä–∞–∑–º–µ—Ä–æ–≤ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\n")
        
        count = 0
        for source, tables in self.sections['data_structures'].items():
            if count < 100:
                content.append(f"\n#### –ò—Å—Ç–æ—á–Ω–∏–∫: `{source}`\n")
                for table in tables[:2]:
                    content.append(table)
                    content.append("")
                    count += 1
                    
        return '\n'.join(content)
        
    def build_roles(self) -> str:
        """–†–∞–∑–¥–µ–ª 6: –†–æ–ª–∏ –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏"""
        content = []
        content.append("### –†–æ–ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –≤ –∂–∏–∑–Ω–µ–Ω–Ω–æ–º —Ü–∏–∫–ª–µ –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤\n")
        
        content.append("#### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–∏")
        content.append("- –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤")
        content.append("- –°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–æ–¥—É–∫—Ü–∏–∏")
        content.append("- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞\n")
        
        content.append("#### –ü–æ—Å—Ç–∞–≤—â–∏–∫–∏ –∏ –¥–∏—Å—Ç—Ä–∏–±—å—é—Ç–æ—Ä—ã")
        content.append("- –õ–æ–≥–∏—Å—Ç–∏–∫–∞ –∏ —Å–∫–ª–∞–¥–∏—Ä–æ–≤–∞–Ω–∏–µ")
        content.append("- –ü–æ–¥–±–æ—Ä –∞–Ω–∞–ª–æ–≥–æ–≤")
        content.append("- –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –ø–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é\n")
        
        content.append("#### –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä—ã –∏ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤—â–∏–∫–∏")
        content.append("- –†–∞—Å—á—ë—Ç –∏ –≤—ã–±–æ—Ä –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤")
        content.append("- –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —É–∑–ª–æ–≤")
        content.append("- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π\n")
        
        content.append("#### –≠–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–æ–Ω–Ω—ã–π –ø–µ—Ä—Å–æ–Ω–∞–ª")
        content.append("- –ú–æ–Ω—Ç–∞–∂ –∏ –¥–µ–º–æ–Ω—Ç–∞–∂")
        content.append("- –û–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –∏ —Å–º–∞–∑–∫–∞")
        content.append("- –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∏ —Ä–µ–º–æ–Ω—Ç\n")
        
        return '\n'.join(content)
        
    def build_usage_scenarios(self) -> str:
        """–†–∞–∑–¥–µ–ª 7: –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        content = []
        content.append("### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è\n")
        
        for scenario, items in self.sections['usage'].items():
            content.append(f"\n#### {scenario}\n")
            for item in items[:2]:
                content.append(f"**–ò—Å—Ç–æ—á–Ω–∏–∫:** `{item['source']}`\n")
                preview = item['content'][:500].replace('\n\n', '\n')
                content.append(preview)
                content.append("...\n")
                
        return '\n'.join(content)
        
    def build_errors(self) -> str:
        """–†–∞–∑–¥–µ–ª 8: –û—à–∏–±–∫–∏ –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è"""
        content = []
        content.append("### –¢–∏–ø–æ–≤—ã–µ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏ –∏ –º–µ—Ç–æ–¥—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏\n")
        
        for error, items in self.sections['errors'].items():
            content.append(f"\n#### {error}\n")
            for item in items[:2]:
                content.append(f"**–ò—Å—Ç–æ—á–Ω–∏–∫:** `{item['source']}`\n")
                preview = item['content'][:300]
                content.append(preview)
                content.append("...\n")
                
        return '\n'.join(content)
        
    def build_relationships(self) -> str:
        """–†–∞–∑–¥–µ–ª 9: –°–≤—è–∑–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏"""
        content = []
        content.append("### –í–∑–∞–∏–º–æ—Å–≤—è–∑–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã\n")
        
        content.append("#### –ò–µ—Ä–∞—Ä—Ö–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤")
        content.append("```")
        content.append("–ü–æ–¥—à–∏–ø–Ω–∏–∫–∏ –∫–∞—á–µ–Ω–∏—è")
        content.append("‚îú‚îÄ‚îÄ –®–∞—Ä–∏–∫–æ–≤—ã–µ")
        content.append("‚îÇ   ‚îú‚îÄ‚îÄ –†–∞–¥–∏–∞–ª—å–Ω—ã–µ")
        content.append("‚îÇ   ‚îú‚îÄ‚îÄ –†–∞–¥–∏–∞–ª—å–Ω–æ-—É–ø–æ—Ä–Ω—ã–µ")
        content.append("‚îÇ   ‚îî‚îÄ‚îÄ –£–ø–æ—Ä–Ω—ã–µ")
        content.append("‚îî‚îÄ‚îÄ –†–æ–ª–∏–∫–æ–≤—ã–µ")
        content.append("    ‚îú‚îÄ‚îÄ –¶–∏–ª–∏–Ω–¥—Ä–∏—á–µ—Å–∫–∏–µ")
        content.append("    ‚îú‚îÄ‚îÄ –ö–æ–Ω–∏—á–µ—Å–∫–∏–µ")
        content.append("    ‚îú‚îÄ‚îÄ –ò–≥–æ–ª—å—á–∞—Ç—ã–µ")
        content.append("    ‚îî‚îÄ‚îÄ –°—Ñ–µ—Ä–∏—á–µ—Å–∫–∏–µ")
        content.append("```\n")
        
        content.append("#### –°–≤—è–∑—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤")
        content.append("- –ì–û–°–¢ ‚Üî ISO - –≤–∑–∞–∏–º–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ")
        content.append("- DIN ‚Üí ISO - –≥–∞—Ä–º–æ–Ω–∏–∑–∞—Ü–∏—è")
        content.append("- JIS ‚Üî ISO - —è–ø–æ–Ω—Å–∫–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã\n")
        
        return '\n'.join(content)
        
    def build_sources(self) -> str:
        """–†–∞–∑–¥–µ–ª 10: –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞"""
        content = []
        content.append("### –ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤\n")
        content.append("| ‚Ññ | –§–∞–π–ª | –ö–∞—Ç–µ–≥–æ—Ä–∏—è |")
        content.append("|---|------|-----------|")
        
        for i, source in enumerate(self.sections['sources'][:1000], 1):
            category = source.split('/')[0] if '/' in source else 'root'
            content.append(f"| {i} | `{source}` | {category} |")
            
        content.append(f"\n**–í—Å–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:** {len(self.sections['sources'])}\n")
        return '\n'.join(content)

def main():
    print("=" * 80)
    print("–ü–û–°–¢–†–û–ï–ù–ò–ï –ü–û–õ–ù–û–ô –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô BEARINGSINFO")
    print("–†–µ–∂–∏–º: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢")
    print("=" * 80)
    
    builder = ComprehensiveKnowledgeBaseBuilder()
    knowledge_base = builder.build_knowledge_base()
    
    output_file = "KNOWLEDGE_BASE_COMPLETE.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(knowledge_base)
        
    file_size = os.path.getsize(output_file)
    print(f"\n‚úì –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Å–æ–∑–¥–∞–Ω–∞: {output_file}")
    print(f"‚úì –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size:,} –±–∞–π—Ç ({file_size/1024/1024:.2f} –ú–ë)")
    print(f"‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {builder.file_count}")
    print(f"‚úì –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {builder.total_lines:,}")
    
if __name__ == "__main__":
    main()
