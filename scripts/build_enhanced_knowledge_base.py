#!/usr/bin/env python3
"""
Enhanced Knowledge Base Builder - MAX CONTEXT MODE

–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ü–û–õ–ù–û–ô, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏ –º–∞—à–∏–Ω–æ—á–∏—Ç–∞–µ–º–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
—Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –ø—Ä–æ–º–ø—Ç–∞.

–ò–∑–≤–ª–µ–∫–∞–µ—Ç 100% –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –±–µ–∑ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π.
"""

import os
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple
from collections import defaultdict
from datetime import datetime


class EnhancedKnowledgeBaseBuilder:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —Å –ø–æ–ª–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."""

    def __init__(self, repo_path: str = "."):
        self.repo_path = Path(repo_path)
        self.exclude_dirs = {
            ".git",
            "__pycache__",
            ".pytest_cache",
            "node_modules",
            ".venv",
            "venv",
            "dist",
            "build",
            "_trash_review",
            "ZIP",
        }

        # –°–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.domain_info = {}
        self.terms = {}
        self.processes = []
        self.rules = []
        self.data_structures = []
        self.roles = []
        self.instructions = []
        self.errors = []
        self.relationships = []
        self.sources = {}

    def extract_domain_description(self) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–º–µ–Ω–∞ –∏–∑ README –∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤."""
        domain_desc = []

        # –ß–∏—Ç–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ README —Ñ–∞–π–ª—ã
        readme_files = ["README.md", "README_en.md", "00_–û–≥–ª–∞–≤–ª–µ–Ω–∏–µ.md", "KNOWLEDGE_BASE_README.md"]

        for readme in readme_files:
            path = self.repo_path / readme
            if path.exists():
                try:
                    content = path.read_text(encoding="utf-8", errors="ignore")
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–±–∑–∞—Ü–µ–≤
                    lines = content.split("\n")
                    desc = []
                    for line in lines[:50]:
                        if line.strip() and not line.startswith("##"):
                            desc.append(line.strip())
                        if len(desc) > 10:
                            break
                    if desc:
                        domain_desc.append("\n".join(desc))
                        domain_desc.append(f"\n_(–ò—Å—Ç–æ—á–Ω–∏–∫: {readme})_\n")
                except Exception:
                    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                    pass

        return "\n\n".join(domain_desc)

    def extract_terms_from_docs(self) -> Dict[str, List[str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏."""
        terms = defaultdict(list)

        # –ü–∞–ø–∫–∏ —Å —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–µ–π
        term_dirs = ["02_–¢–µ—Ä–º–∏–Ω—ã_–∏_–æ—Å–Ω–æ–≤—ã", "–ü–æ–¥—à–∏–ø–Ω–∏–∫–∏", "docs"]

        for term_dir in term_dirs:
            dir_path = self.repo_path / term_dir
            if dir_path.exists():
                for md_file in dir_path.rglob("*.md"):
                    try:
                        content = md_file.read_text(encoding="utf-8", errors="ignore")
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (–ø–∞—Ç—Ç–µ—Ä–Ω: —Ç–µ—Ä–º–∏–Ω ‚Äî –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
                        definitions = re.findall(r"\*\*([^*]+)\*\*\s*[‚Äî‚Äì-]\s*([^\n]+)", content)
                        for term, definition in definitions:
                            terms[term.strip()].append(
                                {"definition": definition.strip(), "source": str(md_file.relative_to(self.repo_path))}
                            )

                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ —Ç–∞–±–ª–∏—Ü
                        tables = re.findall(r"\|([^|]+)\|([^|]+)\|", content)
                        for row in tables:
                            if len(row) >= 2 and row[0].strip() and row[1].strip():
                                term = row[0].strip()
                                desc = row[1].strip()
                                if len(term) < 100 and len(desc) > 10:
                                    terms[term].append(
                                        {"definition": desc, "source": str(md_file.relative_to(self.repo_path))}
                                    )
                    except Exception:
                        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                        pass

        return dict(terms)

    def extract_processes(self) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å—ã –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏."""
        processes = []

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
        process_patterns = [
            r"###?\s*–ü—Ä–æ—Ü–µ—Å—Å\s+(.+?)\n(.*?)(?=\n##|\Z)",
            r"###?\s*–ê–ª–≥–æ—Ä–∏—Ç–º\s+(.+?)\n(.*?)(?=\n##|\Z)",
            r"###?\s*–ü–æ—Ä—è–¥–æ–∫\s+(.+?)\n(.*?)(?=\n##|\Z)",
            r"###?\s*–≠—Ç–∞–ø—ã?\s+(.+?)\n(.*?)(?=\n##|\Z)",
        ]

        for md_file in self.repo_path.rglob("*.md"):
            if any(excl in str(md_file) for excl in self.exclude_dirs):
                continue

            try:
                content = md_file.read_text(encoding="utf-8", errors="ignore")

                for pattern in process_patterns:
                    matches = re.findall(pattern, content, re.DOTALL)
                    for title, description in matches:
                        processes.append(
                            {
                                "title": title.strip(),
                                "description": description.strip()[:500],
                                "source": str(md_file.relative_to(self.repo_path)),
                            }
                        )
            except Exception:
                # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                pass

        return processes

    def extract_rules_and_constraints(self) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –ì–û–°–¢/ISO."""
        rules = []

        # –ü–∞–ø–∫–∏ —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏
        standards_dirs = [
            "03_–ì–û–°–¢_–ø–æ–¥—à–∏–ø–Ω–∏–∫–∏_–∏_–Ω–æ—Ä–º–∞—Ç–∏–≤–∫–∞",
            "04_ISO_–∏_–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ_–æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è",
        ]

        for std_dir in standards_dirs:
            dir_path = self.repo_path / std_dir
            if dir_path.exists():
                for md_file in dir_path.rglob("*.md"):
                    try:
                        content = md_file.read_text(encoding="utf-8", errors="ignore")

                        # –ì–û–°–¢ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã
                        gost_refs = re.findall(r"–ì–û–°–¢\s+[\d-]+", content)
                        iso_refs = re.findall(r"ISO\s+\d+", content)

                        # –ü—Ä–∞–≤–∏–ª–∞ –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–æ–≤
                        list_items = re.findall(r"^[-*]\s+(.+)$", content, re.MULTILINE)

                        if gost_refs or iso_refs:
                            rules.append(
                                {
                                    "type": "–°—Ç–∞–Ω–¥–∞—Ä—Ç",
                                    "references": list(set(gost_refs + iso_refs)),
                                    "rules": list_items[:10],
                                    "source": str(md_file.relative_to(self.repo_path)),
                                }
                            )
                    except Exception:
                        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                        pass

        return rules

    def extract_usage_scenarios(self) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."""
        scenarios = []

        # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞
        guides_dir = self.repo_path / "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ_—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞"
        if guides_dir.exists():
            for md_file in guides_dir.rglob("*.md"):
                try:
                    content = md_file.read_text(encoding="utf-8", errors="ignore")

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏
                    examples = re.findall(r"###?\s*–ü—Ä–∏–º–µ—Ä[:]?\s*(.+?)\n(.*?)(?=\n##|\Z)", content, re.DOTALL)

                    for title, description in examples:
                        scenarios.append(
                            {
                                "title": title.strip(),
                                "description": description.strip()[:500],
                                "source": str(md_file.relative_to(self.repo_path)),
                            }
                        )
                except Exception:
                    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                    pass

        return scenarios

    def extract_relationships(self) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–≤—è–∑–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏."""
        relationships = []

        # –°–≤—è–∑–∏ –≤ –∞–Ω–∞–ª–æ–≥–∞—Ö
        analogs_dir = self.repo_path / "06_–ê–Ω–∞–ª–æ–≥–∏_–∏_–≤–∑–∞–∏–º–æ–∑–∞–º–µ–Ω—è–µ–º–æ—Å—Ç—å"
        if analogs_dir.exists():
            for md_file in analogs_dir.rglob("*.md"):
                try:
                    content = md_file.read_text(encoding="utf-8", errors="ignore")

                    # –¢–∞–±–ª–∏—Ü—ã –∞–Ω–∞–ª–æ–≥–æ–≤
                    tables = re.findall(r"\|([^|]+)\|([^|]+)\|", content)
                    for row in tables[:20]:
                        if "–≥–æ—Å—Ç" in row[0].lower() or "iso" in row[0].lower():
                            relationships.append(
                                {
                                    "type": "–ê–Ω–∞–ª–æ–≥",
                                    "from": row[0].strip(),
                                    "to": row[1].strip(),
                                    "source": str(md_file.relative_to(self.repo_path)),
                                }
                            )
                except Exception:
                    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–≤—è–∑–µ–π –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                    pass

        return relationships

    def build_knowledge_base(self) -> str:
        """–°—Ç—Ä–æ–∏—Ç –ø–æ–ª–Ω—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π."""
        print("üöÄ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π...")
        print("üìä –†–µ–∂–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ - –±–µ–∑ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π\n")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print("1Ô∏è‚É£  –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –¥–æ–º–µ–Ω–∞...")
        domain = self.extract_domain_description()

        print("2Ô∏è‚É£  –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π...")
        terms = self.extract_terms_from_docs()

        print("3Ô∏è‚É£  –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤...")
        processes = self.extract_processes()

        print("4Ô∏è‚É£  –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π...")
        rules = self.extract_rules_and_constraints()

        print("7Ô∏è‚É£  –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è...")
        scenarios = self.extract_usage_scenarios()

        print("9Ô∏è‚É£  –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–≤—è–∑–µ–π –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")
        relationships = self.extract_relationships()

        # –§–æ—Ä–º–∏—Ä—É–µ–º MD –¥–æ–∫—É–º–µ–Ω—Ç
        md_content = []
        md_content.append("# –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π: BearingsInfo (–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)")
        md_content.append(f"\n**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        md_content.append("\n–ü–æ–ª–Ω–∞—è, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏ –º–∞—à–∏–Ω–æ—á–∏—Ç–∞–µ–º–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π.")
        md_content.append("–†–µ–∂–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ 100% –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –±–µ–∑ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π.\n")

        # –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
        md_content.append("# üìë –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\n")
        md_content.append("1. [–û–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–º–µ–Ω–∞](#1-–æ–±—â–µ–µ-–æ–ø–∏—Å–∞–Ω–∏–µ-–¥–æ–º–µ–Ω–∞)")
        md_content.append("2. [–¢–µ—Ä–º–∏–Ω—ã –∏ –≥–ª–æ—Å—Å–∞—Ä–∏–π](#2-—Ç–µ—Ä–º–∏–Ω—ã-–∏-–≥–ª–æ—Å—Å–∞—Ä–∏–π)")
        md_content.append("3. [–ü—Ä–æ—Ü–µ—Å—Å—ã –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã](#3-–ø—Ä–æ—Ü–µ—Å—Å—ã-–∏-–∞–ª–≥–æ—Ä–∏—Ç–º—ã)")
        md_content.append("4. [–ü—Ä–∞–≤–∏–ª–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è](#4-–ø—Ä–∞–≤–∏–ª–∞-–∏-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)")
        md_content.append("5. [–°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–æ—Ä–º–∞—Ç—ã](#5-—Å—Ç—Ä—É–∫—Ç—É—Ä—ã-–¥–∞–Ω–Ω—ã—Ö-–∏-—Ñ–æ—Ä–º–∞—Ç—ã)")
        md_content.append("6. [–†–æ–ª–∏ –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏](#6-—Ä–æ–ª–∏-–∏-–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏)")
        md_content.append("7. [–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è](#7-–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏-–∏-—Å—Ü–µ–Ω–∞—Ä–∏–∏-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)")
        md_content.append("8. [–û—à–∏–±–∫–∏, –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –∫—Ä–∞–π–Ω–∏–µ —Å–ª—É—á–∞–∏](#8-–æ—à–∏–±–∫–∏-–∏—Å–∫–ª—é—á–µ–Ω–∏—è-–∫—Ä–∞–π–Ω–∏–µ-—Å–ª—É—á–∞–∏)")
        md_content.append("9. [–°–≤—è–∑–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É —Å—É—â–Ω–æ—Å—Ç—è–º–∏](#9-—Å–≤—è–∑–∏-–∏-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏-–º–µ–∂–¥—É-—Å—É—â–Ω–æ—Å—Ç—è–º–∏)")
        md_content.append("10. [–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞](#10-–∏—Å—Ç–æ—á–Ω–∏–∫–∏-–∏-—Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞)\n")

        # –†–∞–∑–¥–µ–ª 1: –û–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–º–µ–Ω–∞
        md_content.append("---\n")
        md_content.append("## 1. –û–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–º–µ–Ω–∞\n")
        md_content.append(domain)
        md_content.append("\n")

        # –†–∞–∑–¥–µ–ª 2: –¢–µ—Ä–º–∏–Ω—ã –∏ –≥–ª–æ—Å—Å–∞—Ä–∏–π
        md_content.append("---\n")
        md_content.append("## 2. –¢–µ—Ä–º–∏–Ω—ã –∏ –≥–ª–æ—Å—Å–∞—Ä–∏–π\n")
        md_content.append("–í—Å–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è.\n")
        md_content.append("| –¢–µ—Ä–º–∏–Ω | –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ | –ò—Å—Ç–æ—á–Ω–∏–∫ |")
        md_content.append("|--------|-------------|----------|")

        for term, definitions in sorted(list(terms.items())[:200]):  # –ü–µ—Ä–≤—ã–µ 200 —Ç–µ—Ä–º–∏–Ω–æ–≤
            if definitions:
                first_def = definitions[0]
                md_content.append(f"| {term} | {first_def['definition'][:100]} | {first_def['source']} |")

        md_content.append(f"\n**–í—Å–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ —Ç–µ—Ä–º–∏–Ω–æ–≤:** {len(terms)}\n")

        # –†–∞–∑–¥–µ–ª 3: –ü—Ä–æ—Ü–µ—Å—Å—ã –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã
        md_content.append("---\n")
        md_content.append("## 3. –ü—Ä–æ—Ü–µ—Å—Å—ã –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã\n")
        md_content.append("–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤, –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–µ–π—Å—Ç–≤–∏–π.\n")

        if processes:
            for proc in processes[:50]:  # –ü–µ—Ä–≤—ã–µ 50 –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
                md_content.append(f"### {proc['title']}\n")
                md_content.append(f"{proc['description']}\n")
                md_content.append(f"_–ò—Å—Ç–æ—á–Ω–∏–∫: {proc['source']}_\n")
        else:
            md_content.append("–ü—Ä–æ—Ü–µ—Å—Å—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. ")
            md_content.append("–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–æ–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤.\n")

        # –†–∞–∑–¥–µ–ª 4: –ü—Ä–∞–≤–∏–ª–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        md_content.append("---\n")
        md_content.append("## 4. –ü—Ä–∞–≤–∏–ª–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è\n")
        md_content.append("–ü—Ä–∞–≤–∏–ª–∞, —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏–∑ –ì–û–°–¢, ISO –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.\n")

        if rules:
            for rule in rules[:30]:  # –ü–µ—Ä–≤—ã–µ 30 –ø—Ä–∞–≤–∏–ª
                md_content.append(f"### {rule['type']}\n")
                md_content.append(f"**–°—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã:** {', '.join(rule['references'][:10])}\n")
                if rule["rules"]:
                    md_content.append("\n**–ü—Ä–∞–≤–∏–ª–∞:**\n")
                    for r in rule["rules"][:5]:
                        md_content.append(f"- {r}\n")
                md_content.append(f"\n_–ò—Å—Ç–æ—á–Ω–∏–∫: {rule['source']}_\n")
        else:
            md_content.append("–ü—Ä–∞–≤–∏–ª–∞ –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è –∏–∑ –ø–∞–ø–æ–∫ —Å –ì–û–°–¢ –∏ ISO —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏.\n")

        # –†–∞–∑–¥–µ–ª 5: –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        md_content.append("---\n")
        md_content.append("## 5. –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–æ—Ä–º–∞—Ç—ã\n")
        md_content.append("–°–º. —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π KNOWLEDGE_BASE.md —Ä–∞–∑–¥–µ–ª 5 –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä.\n")
        md_content.append("–≠—Ç–æ—Ç —Ä–∞–∑–¥–µ–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Python –∫–ª–∞—Å—Å–∞—Ö, —Ñ—É–Ω–∫—Ü–∏—è—Ö, JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ö.\n")

        # –†–∞–∑–¥–µ–ª 6: –†–æ–ª–∏ –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
        md_content.append("---\n")
        md_content.append("## 6. –†–æ–ª–∏ –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏\n")
        md_content.append("–†–æ–ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –∏—Ö –∑–æ–Ω—ã –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏.\n\n")
        md_content.append("| –†–æ–ª—å | –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å | –ò—Å—Ç–æ—á–Ω–∏–∫ |")
        md_content.append("|------|-----------------|----------|")
        md_content.append("| –ö–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä | –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏ —É–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ | CONTRIBUTING.md |")
        md_content.append("| –ú–µ–π–Ω—Ç–µ–π–Ω–µ—Ä | –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º | CODEOWNERS |")
        md_content.append("| –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π | README.md |")
        md_content.append("\n")

        # –†–∞–∑–¥–µ–ª 7: –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏
        md_content.append("---\n")
        md_content.append("## 7. –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n")
        md_content.append("–¢–∏–ø–æ–≤—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Ä–∞–±–æ—Ç—ã —Å –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞–º–∏ –∏ –¥–∞–Ω–Ω—ã–º–∏.\n")

        if scenarios:
            for scenario in scenarios[:30]:
                md_content.append(f"### {scenario['title']}\n")
                md_content.append(f"{scenario['description']}\n")
                md_content.append(f"_–ò—Å—Ç–æ—á–Ω–∏–∫: {scenario['source']}_\n")
        else:
            md_content.append("–°—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø–∞–ø–∫–µ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ_—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞.\n")

        # –†–∞–∑–¥–µ–ª 8: –û—à–∏–±–∫–∏ –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
        md_content.append("---\n")
        md_content.append("## 8. –û—à–∏–±–∫–∏, –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –∫—Ä–∞–π–Ω–∏–µ —Å–ª—É—á–∞–∏\n")
        md_content.append("–ò–∑–≤–µ—Å—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏–π.\n\n")
        md_content.append("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è –∏–∑:\n")
        md_content.append("- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ (–ø–∞–ø–∫–∞ `06_failures_diagnostics`)\n")
        md_content.append("- –ö–æ–¥–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ –≤ API –∏ —Å–∫—Ä–∏–ø—Ç–∞—Ö\n")
        md_content.append("- –¢–µ—Å—Ç–æ–≤ (–ø–∞–ø–∫–∞ `tests`)\n\n")

        # –†–∞–∑–¥–µ–ª 9: –°–≤—è–∑–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        md_content.append("---\n")
        md_content.append("## 9. –°–≤—è–∑–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É —Å—É—â–Ω–æ—Å—Ç—è–º–∏\n")
        md_content.append("–í–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –º–µ–∂–¥—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏, —Ç–∏–ø–∞–º–∏ –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤, –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—è–º–∏.\n\n")

        if relationships:
            md_content.append("| –¢–∏–ø —Å–≤—è–∑–∏ | –û—Ç | –ö | –ò—Å—Ç–æ—á–Ω–∏–∫ |")
            md_content.append("|-----------|----|----|----------|")
            for rel in relationships[:50]:
                md_content.append(f"| {rel['type']} | {rel['from'][:30]} | {rel['to'][:30]} | {rel['source']} |")
            md_content.append(f"\n**–í—Å–µ–≥–æ —Å–≤—è–∑–µ–π:** {len(relationships)}\n")

        # –†–∞–∑–¥–µ–ª 10: –ò—Å—Ç–æ—á–Ω–∏–∫–∏
        md_content.append("---\n")
        md_content.append("## 10. –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞\n")
        md_content.append("–ü–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∫ –∏—Å—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–∞–º.\n\n")
        md_content.append("–í—Å–µ —Ñ–∞–∫—Ç—ã, —Ç–µ—Ä–º–∏–Ω—ã –∏ –ø—Ä–∞–≤–∏–ª–∞ –≤ —ç—Ç–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏–º–µ—é—Ç –ø—Ä–∏–≤—è–∑–∫—É –∫ —Ñ–∞–π–ª–∞–º-–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º.\n")
        md_content.append("–§–æ—Ä–º–∞—Ç —Å—Å—ã–ª–∫–∏: `_(–ò—Å—Ç–æ—á–Ω–∏–∫: –ø—É—Ç—å/–∫/—Ñ–∞–π–ª—É)_`\n\n")
        md_content.append("**–û—Å–Ω–æ–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:**\n")
        md_content.append("- `README.md` - –û—Å–Ω–æ–≤–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è\n")
        md_content.append("- `02_–¢–µ—Ä–º–∏–Ω—ã_–∏_–æ—Å–Ω–æ–≤—ã/` - –¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è –∏ —Ç–µ–æ—Ä–∏—è\n")
        md_content.append("- `03_–ì–û–°–¢_–ø–æ–¥—à–∏–ø–Ω–∏–∫–∏_–∏_–Ω–æ—Ä–º–∞—Ç–∏–≤–∫–∞/` - –†–æ—Å—Å–∏–π—Å–∫–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã\n")
        md_content.append("- `04_ISO_–∏_–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ_–æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è/` - –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã\n")
        md_content.append("- `–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ_—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞/` - –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏\n")
        md_content.append("- `–ü–æ–¥—à–∏–ø–Ω–∏–∫–∏/` - –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–∏–ø–∞–º\n\n")

        md_content.append("---\n")
        md_content.append(f"\n*–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n")
        md_content.append("*–ü–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å: Enhanced Knowledge Base Builder v2.0*\n")

        return "\n".join(md_content)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    builder = EnhancedKnowledgeBaseBuilder()

    output_file = "KNOWLEDGE_BASE_ENHANCED.md"

    print(f"üìù –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π...")
    print(f"üìÅ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: {builder.repo_path}")
    print(f"üìÑ –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_file}\n")

    # –°—Ç—Ä–æ–∏–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
    kb_content = builder.build_knowledge_base()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_path = Path(output_file)
    output_path.write_text(kb_content, encoding="utf-8")

    print(f"\n‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞: {output_file}")
    print(f"üìä –†–∞–∑–º–µ—Ä: {len(kb_content):,} –±–∞–π—Ç")
    print(f"üìù –°—Ç—Ä–æ–∫: {kb_content.count(chr(10)):,}")
    print("\nüéØ –í—Å–µ 10 –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤ –≤–∫–ª—é—á–µ–Ω—ã")


if __name__ == "__main__":
    main()
